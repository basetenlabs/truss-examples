# This base image is required for developer build of vLLM
base_image:
  image: nvcr.io/nvidia/pytorch:23.11-py3
  python_executable_path: /usr/bin/python3
build_commands: []
environment_variables:
  HF_TOKEN: ""
external_package_dirs: []
model_metadata:
  main_model: meta-llama/Meta-Llama-3-8B-Instruct
  assistant_model: ibm-fms/llama3-8b-accelerator
  tensor_parallel: 1
  max_num_seqs: 16
model_name: vLLM Speculative Decoding
requirements:
  - git+https://github.com/vllm-project/vllm@9def10664e8b54dcc5c6114f2895bc9e712bf182
resources:
  accelerator: A100
  use_gpu: true
system_packages:
  - python3.10-venv
runtime:
  predict_concurrency: 128
