model_name: "Llama 3.1 8B Instruct SGLang"
python_version: py311
model_metadata:
  example_model_input: {"prompt": "what is the meaning of life"}
  repo_id: meta-llama/Llama-3.1-8B-Instruct
  tensor_parallel: 1
requirements:
  - sglang[all]==0.3.0
  - https://github.com/flashinfer-ai/flashinfer/releases/download/v0.1.6/flashinfer-0.1.6+cu121torch2.4-cp311-cp311-linux_x86_64.whl
model_cache:
  - repo_id: meta-llama/Llama-3.1-8B-Instruct
    use_volume: false
    ignore_patterns:
      - "original/*"
      - "*.pth"
resources:
  accelerator: H100
  use_gpu: true
runtime:
  predict_concurrency: 128
secrets:
  hf_access_token: null
