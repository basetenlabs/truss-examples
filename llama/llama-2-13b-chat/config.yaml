description: Generate text from a prompt with this thirteen billion parameter language
  model.
environment_variables: {}
external_package_dirs: []
model_cache:
- allow_patterns:
  - '*.json'
  - '*.safetensors'
  - '*.model'
  repo_id: meta-llama/Llama-2-13b-chat-hf
model_metadata:
  avatar_url: https://cdn.baseten.co/production/static/explore/meta.png
  cover_image_url: https://cdn.baseten.co/production/static/explore/llama.png
  example_model_input:
    num_beams: 4
    prompt: What's the meaning of life?
    temperature: 0.1
    top_p: 0.75
  repo_id: meta-llama/Llama-2-13b-chat-hf
  tags:
  - text-generation
model_name: LLaMA 2 13B Chat
python_version: py38
requirements:
- accelerate==0.22.0
- bitsandbytes==0.41.1
- einops==0.6.1
- faker==19.3.1
- hf-transfer==0.1.4
- peft==0.5.0
- protobuf==3.20.3
- safetensors==0.3.3
- scipy==1.10.1
- sentencepiece==0.1.99
- torch==2.0.1
- transformers==4.32.1
resources:
  accelerator: A100
  cpu: '3'
  memory: 14Gi
  use_gpu: true
secrets:
  hf_access_token: ENTER HF ACCESS TOKEN HERE
system_packages: []
