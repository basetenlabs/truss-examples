build:
  arguments:
    model_id: meta-llama/Llama-2-7b-chat-hf
  model_server: TGI
environment_variables: {}
external_package_dirs: []
model_metadata: {}
model_name: Llama 7B Chat TGI
python_version: py311
requirements: []
resources:
  accelerator: A100
  cpu: '4'
  memory: 16Gi
  use_gpu: true
secrets:
  hf_access_token: null
system_packages: []
runtime:
  predict_concurrency: 256
