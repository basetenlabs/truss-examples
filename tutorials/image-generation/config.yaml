# # Setting up the config yaml
#
# Running SDXL requires a handful of Python libraries, including
# diffusers, transformers, and others.
description: "A tutorial example showing how to deploy Stable Diffusion XL on Baseten."
environment_variables: {}
external_package_dirs: []
model_metadata:
  repo_id: stabilityai/stable-diffusion-xl-base-1.0
  example_model_input:
    { "prompt": "A tree in a field under the night sky", "use_refiner": true }
model_name: Stable Diffusion XL
python_version: py39
requirements:
  - transformers==4.34.0
  - accelerate==0.23.0
  - safetensors==0.4.0
  - git+https://github.com/basetenlabs/diffusers.git@9a353290b1497023d4745a719ec02c50f680499a
  - invisible-watermark>=0.2.0
  - xformers==0.0.22
  - numpy==1.26.4
# ## Configuring resources for SDXL 1.0
#
# Note that we need an A10G to run this model.
resources:
  accelerator: A10G
  cpu: 3500m
  memory: 20Gi
  use_gpu: true
secrets: {}
# ## System Packages
#
# Running diffusers requires `ffmpeg` and a couple other system
# packages.
system_packages:
  - ffmpeg
  - libsm6
  - libxext6
# ## Enabling Caching
#
# SDXL is a very large model, and downloading it could take up to 10 minutes. This means
# that the cold start time for this model is long. We can solve that by using our build
# caching feature. This moves the model download to the build stage of your model--
# caching the model will take about 10 minutes initially but you will get ~9s cold starts
# subsequently.
#
# To enable caching, add the following to the config:
# ```yaml
# model_cache:
#   - repo_id: madebyollin/sdxl-vae-fp16-fix
#     revision: main
#     allow_patterns:
#       - config.json
#       - diffusion_pytorch_model.safetensors
#     use_volume: true
#     volumne_folder: "sdxl-vae-fp16-fix"
#   - repo_id: stabilityai/stable-diffusion-xl-base-1.0
#     allow_patterns:
#       - "*.json"
#       - "*.fp16.safetensors"
#       - sd_xl_base_1.0.safetensors
#     use_volume: true
#     volumne_folder: "sdxl-base"
#   - repo_id: stabilityai/stable-diffusion-xl-refiner-1.0
#     allow_patterns:
#       - "*.json"
#       - "*.fp16.safetensors"
#       - sd_xl_refiner_1.0.safetensors
#     use_volume: true
#     volumne_folder: "sdxl-refiner"
# ```
# # Deploy the model
#
# Deploy the model like you would other Trusses, with:
# ```bash
# $ truss push
# ```
# You can then invoke the model with:
# ```bash
# $ truss predict -d '{"prompt": "A tree in a field under the night sky", "use_refiner": true}'
# ```
