base_image:
  #commit: 302f3aca7ea3f57842881cb2ae0062c19ad24758
  image: public.ecr.aws/q9t5s3a7/vllm-ci-postmerge-repo:c494f96fbcf5e9f19f59e3dea6c2780aeb6c567f
model_metadata:
  repo_id: openai/gpt-oss-20b
  example_model_input: {
    "model": "openai/gpt-oss-20b",
    "messages": [
      {
      "role": "user",
      "content": "Given an array of integers nums and an integer target, return indices of the two numbers such that they add up to target. You may assume that each input would have exactly one solution, and you may not use the same element twice. You can return the answer in any order. class Solution: def twoSum(self, nums: List[int], target: int) -> List[int]:"
      }
    ],
    "stream": true,
    "max_tokens": 512,
    "temperature": 0.5
  }
  tags:
  - openai-compatible
# cache_internal:
# - repo_id: openai/gpt-oss-20b
docker_server:
  start_command: sh -c /app/data/do.sh
  readiness_endpoint: /health
  liveness_endpoint: /health
  predict_endpoint: /v1/chat/completions
  server_port: 8000
environment_variables:
  VLLM_LOGGING_LEVEL: INFO
  hf_access_token: null
resources:
  accelerator: H100:1
  use_gpu: true
secrets:
  hf_access_token: null
runtime:
  predict_concurrency : 64
model_name: openai/gpt-oss-20b
