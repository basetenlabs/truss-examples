description: "Qwen3 Coder Next for code generation"
model_metadata:
  repo_id: "Qwen/Qwen3-Coder-Next-FP8"
  example_model_input:
    messages:
      - role: system
        content: "You are a helpful assistant."
      - role: user
        content: "What is the meaning of life?"
    stream: true
    model: Qwen/Qwen3-Coder-Next
    max_tokens: 32768
    temperature: 0.7
  tags:
    - openai-compatible

base_image:
  image: lmsysorg/sglang:nightly-dev-20260202-9227d4f7


build_commands:
  - pip uninstall -y sglang
  - git clone https://github.com/sgl-project/sglang.git && cd sglang && pip install --upgrade pip && pip install -e "python" && pip install nvidia-cudnn-cu12>=9.16.0.29

docker_server:
  start_command: sh -c 'python -m sglang.launch_server --model Qwen/Qwen3-Coder-Next-FP8 --port 30000 --tp-size 2 --tool-call-parser qwen3_coder'
  readiness_endpoint: /health_generate
  liveness_endpoint: /health_generate
  predict_endpoint: /v1/chat/completions
  server_port: 30000
requirements: []
system_packages:
- tmux
- htop
- nload
resources:
  accelerator: H100:2
  use_gpu: true
runtime:
  predict_concurrency : 64
model_name: Qwen3-Coder-Next
