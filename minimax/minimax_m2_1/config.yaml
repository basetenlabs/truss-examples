base_image:
  image: lmsysorg/sglang:nightly-dev-20260126-48f4340b
docker_server:
  liveness_endpoint: /health_generate
  predict_endpoint: /v1/chat/completions
  readiness_endpoint: /health_generate
  server_port: 8000
  start_command: sh -c "truss-transfer-cli && find /app/model_cache/checkpoint -type f -print0 | xargs -0 -P 0 -I {} dd if={} of=/dev/null bs=4M && python3 -m sglang.launch_server --model-path /app/model_cache/checkpoint --tp-size 8 --ep-size 8 --tool-call-parser minimax-m2 --trust-remote-code --host 0.0.0.0 --reasoning-parser minimax --port 8000 --mem-fraction-static 0.85"
#environment_variables:
#  SGLANG_ALLOW_OVERWRITE_LONGER_CONTEXT_LEN: 1
model_cache:
- allow_patterns:
  - '*.json'
  - '*.safetensors'
  - '*.txt'
  - '*.model'
  - '*.py'
  - '*.jinja'
  repo_id: MiniMaxAI/MiniMax-M2.1
  revision: 927ea2b64008fe4a1e31a4e107a6b75916b3b44a
  use_volume: true
  volume_folder: checkpoint
model_metadata:
  example_model_input:
    max_tokens: 4096
    messages:
    - content: You are a helpful assistant.
      role: system
    - content: Who won the world series in 2020?
      role: user
    model: MiniMaxAI/MiniMax-M2
    stream: true
    temperature: 0.6
  model_name: MiniMax-M2
  tags:
  - openai-compatible
model_name: minimax
resources:
  accelerator: H100:8
  cpu: '1'
  memory: 2Gi
  use_gpu: true
runtime:
  health_checks:
    restart_check_delay_seconds: 1200
    restart_threshold_seconds: 600
    stop_traffic_threshold_seconds: 1800
  is_websocket_endpoint: false
  predict_concurrency: 32
  transport:
    kind: http
