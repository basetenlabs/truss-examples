model_name: Hello Model Cache Qwen
python_version: py311
requirements: ["torch"]
resources:
  accelerator: null
  cpu: "1"
  memory: 8Gi
  use_gpu: false
secrets: { hf_access_token: null } # null is encouraged, as this will automatically use the one provided by baseten.co
model_cache:
  - repo_id: madebyollin/sdxl-vae-fp16-fix
    revision: 207b116dae70ace3637169f1ddd2434b91b3a8cd
    use_volume: true
    volume_folder: sdxl-vae-fp16
    allow_patterns:
      - config.json
      - diffusion_pytorch_model.safetensors
    runtime_secret_name: hf_access_token
    kind: "hf"
  - repo_id: stabilityai/stable-diffusion-xl-base-1.0
    revision: 462165984030d82259a11f4367a4eed129e94a7b
    use_volume: true
    volume_folder: stable-diffusion-xl-base
    allow_patterns:
      - "*.json"
      - "*.fp16.safetensors"
      - sd_xl_base_1.0.safetensors
    runtime_secret_name: hf_access_token
    kind: "hf"
