description: "Datadog metrics integration example with Qwen3 30B"
base_image:
  image: chriswirick/truss_fastapi_datadog_vllm:v0.11.0h
docker_server:
  liveness_endpoint: /health
  predict_endpoint: /v1/chat/completions
  readiness_endpoint: /health
  server_port: 8000
  start_command: sh -c "export DD_API_KEY=$(cat /secrets/dd_api_key | tr -d '\n\r' | xargs) && mkdir -p /tmp/datadog-agent /var/log/datadog && /opt/datadog-agent/bin/agent/agent run 2>&1 & sleep 3 && HF_TOKEN=$(cat /secrets/hf_access_token) vllm serve Qwen/Qwen3-30B-A3B --reasoning-parser deepseek_r1 --served-model-name qwen30b --port 8000"
environment_variables:
  DD_SITE: "us5.datadoghq.com"
  DD_HOSTNAME: "truss-vllm-server"
  DD_SERVICE: "truss-vllm"
  DD_ENV: "production"
  DD_RUN_PATH: "/tmp/datadog-agent"
  DD_AUTH_TOKEN_FILE_PATH: "/tmp/datadog-agent/auth_token"
  DD_INVENTORIES_CHECKS_ENABLED: "false"
  DD_OTLP_CONFIG_RECEIVER_PROTOCOLS_GRPC_ENDPOINT: ""
  DD_CLOUD_PROVIDER_METADATA: "[]"
  VLLM_LOGGING_LEVEL: WARNING
model_metadata:
  repo_id: Qwen/Qwen3-30B-A3B
  example_model_input:
    messages:
      - role: system
        content: "You are a helpful assistant."
      - role: user
        content: "What does Tongyi Qianwen mean?"
    stream: false
    model: "qwen30b"
    max_tokens: 512
    temperature: 0.7
  tags:
    - openai-compatible
resources:
  accelerator: H100:1
  use_gpu: true
runtime:
  predict_concurrency: 32
model_name: truss_fastapi_datadog
secrets:
  dd_api_key: null
  hf_access_token: null
