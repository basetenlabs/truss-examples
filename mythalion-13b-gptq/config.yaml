build:
  arguments:
    endpoint: generate
    model_id: TheBloke/Mythalion-13B-GPTQ
    quantize: gptq
  model_server: TGI
environment_variables: {}
model_metadata:
  example_model_input: {"inputs": "Whats the meaning of life"}
external_package_dirs: []
model_name: mythalion-13B
python_version: py39
requirements: []
resources:
  accelerator: A10G
  use_gpu: true
secrets: {}
system_packages: []
runtime:
  predict_concurrency: 128
