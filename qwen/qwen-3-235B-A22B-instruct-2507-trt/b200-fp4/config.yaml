model_name: Qwen3-235B-A22B FP4 B200
model_metadata:
  example_model_input:
    messages:
      - role: system
        content: "You are a helpful assistant."
      - role: user
        content: "What does Tongyi Qianwen mean?"
    model: Qwen/Qwen3-235B-A22B-Instruct-2507
    stream: true
    max_tokens: 512
    temperature: 0.6
  tags:
    - openai-compatible
resources:
  accelerator: B200:4
  cpu: "1"
  memory: 10Gi
  use_gpu: true
environment_variables:
  BAD_TOKEN_ID_SEQ_CHECK_ENABLED: 1
  TRTLLM_ENABLE_PDL: 1
  TRTLLM_NVFP4_GEMM_BACKEND: cutlass
weights:
  - source: "hf://nvidia/Qwen3-235B-A22B-Instruct-2507-NVFP4@main"
    mount_location: "/models/Qwen3-235B-A22B-Instruct-2507-NVFP4"
    auth_secret_name: "hf_access_token"
trt_llm:
  build:
    checkpoint_repository:
      repo: michaelfeil/empty-model
      revision: main
      source: HF
  inference_stack: v2
  runtime:
    max_batch_size: 64
    max_num_tokens: 16384
    max_seq_len: 32768
    enable_chunked_prefill: true
    tensor_parallel_size: 4
    served_model_name: Qwen/Qwen3-235B-A22B-Instruct-2507
    patch_kwargs:
      model_path: /models/Qwen3-235B-A22B-Instruct-2507-NVFP4
      backend: pytorch
      max_beam_width: 1
      max_input_len: 32768
      tokenizer_limit_length: 32768
      disable_overlap_scheduler: false
      enable_iter_perf_stats: true
      guided_decoding_backend: xgrammar
      tool_call_parser: qwen25
      trust_remote_code: 1
      moe_expert_parallel_size: 4
      moe_config:
        backend: TRTLLM
        use_low_precision_moe_combine: true
      kv_cache_config:
        dtype: fp8
        free_gpu_memory_fraction: 0.9
        enable_block_reuse: true
        enable_partial_reuse: true
        event_buffer_max_size: 1024
      cuda_graph_config:
        enable_padding: true
  version_overrides:
    v2_llm_version: trtllm-gpu-1.3.0rc2-6bfe58f1a-d40e7fc8d3
runtime:
  predict_concurrency: 32
  health_checks:
    restart_check_delay_seconds: 1800
    restart_threshold_seconds: 30
    stop_traffic_threshold_seconds: 120
