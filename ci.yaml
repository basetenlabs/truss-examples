# Canonical list of all examples in the repository.
# test_all.py (Test 8) validates that every path here exists and loads with truss.load().
tests:
  # ── tutorials ──────────────────────────────────────────────────────────────
  - tutorials/getting-started-bert
  - tutorials/llm-basics
  - tutorials/llm-streaming
  - tutorials/image-generation
  - tutorials/speech-to-text
  - tutorials/cached-weights
  - tutorials/system-packages
  - tutorials/dynamic-batching
  - tutorials/private-huggingface

  # ── llm ────────────────────────────────────────────────────────────────────
  # llm/cogito
  - llm/cogito/cogito-v2-preview-deepseek-671B-MoE-vllm
  - llm/cogito/cogito-v2-preview-llama-109B-MoE-vllm
  - llm/cogito/cogito-v2-preview-llama-405B-vllm
  - llm/cogito/cogito-v2-preview-llama-70B-vllm
  # llm/cogvlm
  - llm/cogvlm
  # llm/deepseek
  - llm/deepseek/deepseek-ocr
  - llm/deepseek/deepseek-vl2
  - llm/deepseek/engine-deepseek-r1-distill-llama-70b
  - llm/deepseek/engine-deepseek-r1-distill-llama-8b
  - llm/deepseek/engine-deepseek-r1-distill-qwen-14b
  - llm/deepseek/engine-deepseek-r1-distill-qwen-32b
  - llm/deepseek/engine-deepseek-r1-distill-qwen-7b
  # llm/falcon
  - llm/falcon/falcon3-3B-trt-llm-engine-high-throughput
  # llm/gemma
  - llm/gemma/gemma-2-27b-it-vllm
  - llm/gemma/gemma-2-9b-it-vllm
  - llm/gemma/gemma-3-27b-it
  # llm/llama
  - llm/llama/engine-llama-3-1-70b-instruct
  - llm/llama/engine-llama-3-1-8b-instruct
  - llm/llama/engine-llama-3-3-70b-instruct
  - llm/llama/engine-llama-3.1-405b-instruct
  - llm/llama/llama-3-1-405b-instruct
  - llm/llama/llama-3-1-70b-instruct
  - llm/llama/llama-3-1-8b-instruct
  - llm/llama/llama-3-1-8b-instruct-sglang
  - llm/llama/llama-3-2-11b-vision-instruct
  - llm/llama/llama-3-70b-instruct
  - llm/llama/llama-3-8b-instruct
  - llm/llama/llama-4-maverick-17b-128e-instruct-fp8-vllm
  - llm/llama/llama-4-scout-17b-16e-instruct-bf16-vllm
  - llm/llama/tinyllama-1.1B-chat-v1.0
  # llm/llava
  - llm/llava/llava-1.6-sgl
  - llm/llava/llava-v1.5-7b
  - llm/llava/llava-v1.6-34b
  # llm/lora
  - llm/lora/engine-lora
  - llm/lora/sglang-lora
  - llm/lora/vllm-lora
  # llm/midnight
  - llm/midnight
  # llm/minimax
  - llm/minimax/minimax-m2-1
  # llm/mistral
  - llm/mistral/engine-devstral
  - llm/mistral/engine-mistral-small-3
  - llm/mistral/engine-mixtral-8x22b-instruct
  - llm/mistral/engine-mixtral-8x7b-instruct
  - llm/mistral/mistral-7b
  - llm/mistral/mistral-small-3.1
  - llm/mistral/mixtral-8x22b
  - llm/mistral/mixtral-8x22b-trt-int8-weights-only
  - llm/mistral/mixtral-8x7b-instruct-trt-llm
  - llm/mistral/mixtral-8x7b-instruct-trt-llm-h100
  - llm/mistral/mixtral-8x7b-instruct-trt-llm-weights-only-quant
  - llm/mistral/mixtral-8x7b-instruct-trt-llm-weights-only-quant-h100
  - llm/mistral/mixtral-8x7b-instruct-vllm
  - llm/mistral/mixtral-8x7b-instruct-vllm-a100-t-tp2
  - llm/mistral/pixtral-12b
  # llm/nemotron
  - llm/nemotron/llama-3-1-nemotron-70b-instruct
  - llm/nemotron/llama-3-1-nemotron-nano-vl-8b-v1
  - llm/nemotron/llama-nemoretriever-colembed-3b-v1
  - llm/nemotron/nemotron-3-nano
  - llm/nemotron/nemotron-3-nano-nvfp4
  - llm/nemotron/nemotron-nano-12b-v2-vl-bf16
  - llm/nemotron/nemotron-ultra-253b
  # llm/nsql
  - llm/nsql
  # llm/openai
  - llm/openai/gpt-oss-120b
  - llm/openai/gpt-oss-20b
  # llm/personaplex
  - llm/personaplex-7b-v1
  # llm/phi
  - llm/phi/phi-3-mini-128k-instruct
  - llm/phi/phi-3-mini-4k-instruct
  - llm/phi/phi-3.5-mini
  # llm/qwen
  - llm/qwen/engine-qwen-2-5-14b-coder-instruct
  - llm/qwen/engine-qwen-2-5-14b-instruct
  - llm/qwen/engine-qwen-2-5-32b-coder-instruct
  - llm/qwen/engine-qwen-2-5-32b-instruct
  - llm/qwen/engine-qwen-2-5-3b-instruct
  - llm/qwen/engine-qwen-2-5-72b-instruct
  - llm/qwen/engine-qwen-2-5-72b-math-instruct
  - llm/qwen/engine-qwen-2-5-7b-coder-instruct
  - llm/qwen/engine-qwen-2-5-7b-instruct
  - llm/qwen/engine-qwen-2-5-7b-math-instruct
  - llm/qwen/engine-qwen-3-06b
  - llm/qwen/engine-qwen-3-30b-a3b-instruct-2507
  - llm/qwen/engine-qwen-3-32b
  - llm/qwen/engine-qwen-3-4b
  - llm/qwen/qwen-3-235B-A22B-instruct-2507-trt
  - llm/qwen/qwen-3-235B-sglang
  - llm/qwen/qwen-3-30B-A3-coder
  - llm/qwen/qwen-3-30B-A3-sglang
  - llm/qwen/qwen-3-30B-A3-vllm
  - llm/qwen/qwen-3-32B-sglang
  - llm/qwen/qwen-3-next-80B-A3-instruct-sglang
  - llm/qwen/qwen-3-next-80B-A3-thinking-sglang
  - llm/qwen/qwen-3-vl-30b-a3b-instruct
  - llm/qwen/qwen-3-vl-30b-a3b-thinking
  - llm/qwen/qwen-3-vl-32b
  - llm/qwen/qwen-coder-next
  - llm/qwen/qwen-image
  - llm/qwen/qwen-vl
  # llm/seed
  - llm/seed/seed-llm
  # llm/z-ai
  - llm/z-ai/glm-4-5-air-fp8
  - llm/z-ai/glm-4-5-fp8
  - llm/z-ai/glm-4-5-v
  - llm/z-ai/glm-4-6-fp8
  - llm/z-ai/glm-4-7-flash

  # ── embeddings ─────────────────────────────────────────────────────────────
  # embeddings/bei
  - embeddings/bei/alibaba-nlp-gte-modernbert-base-embedding
  - embeddings/bei/alibaba-nlp-gte-qwen2-1.5b-instruct-embedding
  - embeddings/bei/alibaba-nlp-gte-qwen2-7b-instruct-embedding
  - embeddings/bei/alibaba-nlp-gte-reranker-modernbert-base
  - embeddings/bei/allenai-llama-3.1-tulu-3-8b-reward-model-fp8
  - embeddings/bei/baai-bge-en-icl-embedding-fp8
  - embeddings/bei/baai-bge-large-en-v1.5-embedding
  - embeddings/bei/baai-bge-m3-embedding-dense
  - embeddings/bei/baai-bge-multilingual-gemma2-multilingual-embedding
  - embeddings/bei/baai-bge-reranker-large
  - embeddings/bei/baai-bge-reranker-large/BEI-Bert-baai-bge-reranker-large
  - embeddings/bei/baai-bge-reranker-v2-m3-multilingual
  - embeddings/bei/baseten-example-meta-llama-3-70b-instructforsequenceclassification-fp8
  - embeddings/bei/codefuse-ai-f2llm-4b-embedding-fp8
  - embeddings/bei/google-embeddinggemma-300m
  - embeddings/bei/intfloat-e5-mistral-7b-instruct-embedding-fp8
  - embeddings/bei/intfloat-multilingual-e5-large-instruct
  - embeddings/bei/jina-ai-jina-embeddings-v2-base-en
  - embeddings/bei/jinaai-jina-code-embeddings-0.5b-fp8
  - embeddings/bei/jinaai-jina-embeddings-v2-base-code
  - embeddings/bei/mixedbread-ai-mxbai-embed-large-v1-embedding
  - embeddings/bei/mixedbread-ai-mxbai-embed-large-v1-embedding/BEI-mixedbread-ai-mxbai-embed-large-v1-embedding
  - embeddings/bei/mixedbread-ai-mxbai-rerank-base-v2-reranker-fp8
  - embeddings/bei/mixedbread-ai-mxbai-rerank-large-v2-reranker-fp8
  - embeddings/bei/ncbi-medcpt-cross-encoder-reranker
  - embeddings/bei/ner-bert-base-ner-uncased
  - embeddings/bei/nomic-ai-nomic-embed-code-fp8
  - embeddings/bei/nomic-ai-nomic-embed-text-v1.5
  - embeddings/bei/nomic-ai-nomic-embed-text-v2-moe
  - embeddings/bei/nvidia-llama-embed-nemotron-8b
  - embeddings/bei/nvidia-llama-nemotron-embed-1b-v2
  - embeddings/bei/papluca-xlm-roberta-base-language-detection-classification
  - embeddings/bei/qwen-qwen3-embedding-0.6b-fp8
  - embeddings/bei/qwen-qwen3-embedding-4b-fp4
  - embeddings/bei/qwen-qwen3-embedding-4b-fp8
  - embeddings/bei/qwen-qwen3-embedding-8b-fp8
  - embeddings/bei/qwen-qwen3-reranker-0.6b-fp8
  - embeddings/bei/qwen-qwen3-reranker-4b-fp8
  - embeddings/bei/qwen-qwen3-reranker-8b-fp4
  - embeddings/bei/qwen-qwen3-reranker-8b-fp8
  - embeddings/bei/redis-langcache-embed-v2
  - embeddings/bei/salesforce-sfr-embedding-mistral-fp8
  - embeddings/bei/samlowe-roberta-base-go_emotions-classification
  - embeddings/bei/sentence-transformers-all-minilm-l6-v2-embedding
  - embeddings/bei/skywork-skywork-reward-llama-3.1-8b-v0.2-reward-model-fp8
  - embeddings/bei/snowflake-snowflake-arctic-embed-l-v2.0
  - embeddings/bei/tanaos-tanaos-ner-v1
  - embeddings/bei/taylorai-bge-micro-v2
  - embeddings/bei/voyageai-voyage-4-nano
  - embeddings/bei/whereisai-uae-large-v1-embedding
  # embeddings/tei
  - embeddings/tei/alibaba-nlp-gte-modernbert-base-embedding
  - embeddings/tei/alibaba-nlp-gte-qwen2-1.5b-instruct-embedding
  - embeddings/tei/alibaba-nlp-gte-qwen2-7b-instruct-embedding
  - embeddings/tei/alibaba-nlp-gte-reranker-modernbert-base
  - embeddings/tei/baai-bge-reranker-large
  - embeddings/tei/google-embeddinggemma-300m
  - embeddings/tei/intfloat-multilingual-e5-large-instruct
  - embeddings/tei/jina-ai-jina-embeddings-v2-base-en
  - embeddings/tei/jinaai-jina-embeddings-v2-base-code
  - embeddings/tei/mixedbread-ai-mxbai-embed-large-v1-embedding
  - embeddings/tei/nomic-ai-nomic-embed-text-v1.5
  - embeddings/tei/nomic-ai-nomic-embed-text-v2-moe
  - embeddings/tei/redis-langcache-embed-v2
  - embeddings/tei/sentence-transformers-all-minilm-l6-v2-embedding
  - embeddings/tei/taylorai-bge-micro-v2
  # embeddings/other
  - embeddings/clip
  - embeddings/text-embeddings-inference

  # ── image ──────────────────────────────────────────────────────────────────
  - image/comfyui
  - image/comfyui/examples/anime-style-transfer
  - image/control-net-qrcode
  - image/deepfloyd-xl
  - image/dis-segmentation
  - image/flux-dev-trt-b200
  - image/flux/dev
  - image/flux/schnell
  - image/fotographer/zenctrl
  - image/gfp-gan
  - image/image-segmentation
  - image/ip-adapter
  - image/magic-animate
  - image/playground-v2-aesthetic
  - image/sana/sana-1600m
  - image/sana/sana-600m
  - image/segment-anything
  - image/stable-diffusion/dreamshaper-lcm
  - image/stable-diffusion/playground-v2-trt
  - image/stable-diffusion/sd-textual-inversion
  - image/stable-diffusion/sd-turbo
  - image/stable-diffusion/sdxl-controlnet
  - image/stable-diffusion/sdxl-controlnet-canny
  - image/stable-diffusion/sdxl-controlnet-depth
  - image/stable-diffusion/sdxl-lightning
  - image/stable-diffusion/sdxl-lora
  - image/stable-diffusion/sdxl-lora-swapping
  - image/stable-diffusion/sdxl-turbo
  - image/stable-diffusion/stable-diffusion
  - image/stable-diffusion/stable-diffusion-3-medium
  - image/stable-diffusion/stable-diffusion-inpainting-trt
  - image/stable-diffusion/stable-diffusion-xl-1.0
  - image/stable-diffusion/stable-diffusion-xl-1.0-trt
  - image/stable-diffusion/stable-diffusion-xl-1.0-trt-h100
  - image/stable-diffusion/stable-video-diffusion

  # ── audio ──────────────────────────────────────────────────────────────────
  - audio/audiogen-medium
  - audio/chatterbox-tts
  - audio/kokoro
  - audio/metavoice-1b
  - audio/musicgen-large
  - audio/musicgen-melody
  - audio/nvidia-parakeet
  - audio/orpheus-3b-websockets
  - audio/orpheus-best-performance
  - audio/piper-tts
  - audio/qwen-asr
  - audio/qwen-omni
  - audio/qwen-omni-thinker
  - audio/sesame-csm-1b
  - audio/ultravox
  - audio/voxtral-streaming-4b
  - audio/whisper/faster-whisper-small
  - audio/whisper/faster-whisper-v2
  - audio/whisper/faster-whisper-v3
  - audio/whisper/whisper-openai
  - audio/whisper/whisper-streaming
  - audio/whisper/whisper-v3
  - audio/whisper/whisper-v3-base64
  - audio/whisper/whisperx
  - audio/xtts-streaming
  - audio/xtts-v2

  # ── optimized ──────────────────────────────────────────────────────────────
  # optimized/bisv2
  - optimized/bisv2/deepseek-ai-deepseek-r1-distill-llama-70b-fp4
  - optimized/bisv2/meta-llama-llama-3.2-3b-instruct-fp4-mlp-only
  - optimized/bisv2/meta-llama-llama-3.2-3b-instruct-fp8
  - optimized/bisv2/meta-llama-llama-3.3-70b-instruct-fp4
  - optimized/bisv2/nvidia-llama-3.1-8b-instruct-fp4
  - optimized/bisv2/nvidia-qwen3-30b-a3b-fp4
  - optimized/bisv2/nvidia-qwen3-8b-fp4
  - optimized/bisv2/qwen-qwen2.5-coder-7b-instruct
  - optimized/bisv2/qwen-qwen2.5-coder-7b-instruct-fp4
  - optimized/bisv2/qwen-qwen3-32b-fp4
  - optimized/bisv2/qwen-qwen3-4b-fp8
  # optimized/briton
  - optimized/briton/deepseek-ai-deepseek-r1-distill-llama-70b-fp8
  - optimized/briton/deepseek-ai-deepseek-r1-distill-qwen-32b-fp8
  - optimized/briton/google-gemma-3-1b-it
  - optimized/briton/google-gemma-3-270m-it
  - optimized/briton/google-gemma-3-27b-it
  - optimized/briton/google-gemma-3-27b-it-speculative-lookahead
  - optimized/briton/meta-llama-llama-3.1-405b-fp8
  - optimized/briton/meta-llama-llama-3.1-8b-instruct-with-speculative-lookahead-decoding-fp8
  - optimized/briton/meta-llama-llama-3.2-1b-instruct-fp8
  - optimized/briton/meta-llama-llama-3.2-3b-instruct
  - optimized/briton/meta-llama-llama-3.2-3b-instruct-calib-dataset-fp8
  - optimized/briton/meta-llama-llama-3.2-3b-instruct-fp8
  - optimized/briton/meta-llama-llama-3.3-70b-instruct-fp4
  - optimized/briton/meta-llama-llama-3.3-70b-instruct-fp8
  - optimized/briton/meta-llama-llama-3.3-70b-instruct-tp4-fp8
  - optimized/briton/microsoft-phi-4-fp8
  - optimized/briton/mistralai-mistral-7b-instruct-v0.3
  - optimized/briton/mistralai-mistral-small-24b-instruct-2501-fp8
  - optimized/briton/qwen-qwen2.5-72b-instruct-tp2-fp8
  - optimized/briton/qwen-qwen2.5-7b-instruct-with-speculative-lookahead-decoding-fp8
  - optimized/briton/qwen-qwen2.5-coder-7b-instruct-calib-dataset-fp4-mlp-only
  - optimized/briton/qwen-qwen2.5-coder-7b-instruct-min-latency-fp8
  - optimized/briton/qwen-qwen3-235b-a22b-instruct-2507-fp8
  - optimized/briton/qwen-qwen3-30b-a3b
  - optimized/briton/qwen-qwen3-30b-a3b-fp8
  - optimized/briton/qwen-qwen3-30b-a3b-instruct-2507-fp8
  - optimized/briton/qwen-qwen3-32b-fp4
  - optimized/briton/qwen-qwen3-32b-fp4-mlp-only
  - optimized/briton/qwen-qwen3-32b-fp8
  - optimized/briton/qwen-qwen3-8b-min-latency-fp8
  - optimized/briton/qwen-qwq-32b-reasoning-fp8
  - optimized/briton/qwen-qwq-32b-reasoning-with-speculative-fp8
  - optimized/briton/tiiuae-falcon3-10b-instruct-fp8

  # ── infrastructure ─────────────────────────────────────────────────────────
  - infrastructure/autodesk-wala
  - infrastructure/binocular
  - infrastructure/custom-engine-builder-control
  - infrastructure/custom-server/deepseek-v2-5-instruct-sglang
  - infrastructure/custom-server/infinity-embedding-server
  - infrastructure/custom-server/llama3-70b-instruct-lmdeploy
  - infrastructure/custom-server/llama3-70b-instruct-sglang
  - infrastructure/custom-server/llama3-8b-instruct-lmdeploy
  - infrastructure/custom-server/llama3-8b-instruct-sglang
  - infrastructure/custom-server/pixtral-12b
  - infrastructure/custom-server/ultravox-0.4
  - infrastructure/custom-server/ultravox-0.5-8b
  - infrastructure/custom-server/ultravox-0.6-70b
  - infrastructure/custom-server/voxtral-mini-3b-2507
  - infrastructure/custom-server/voxtral-small-24b-2507
  - infrastructure/grpc
  - infrastructure/jsonformatter
  - infrastructure/layoutlm-document-qa
  - infrastructure/llama-cpp-server
  - infrastructure/metrics/datadog
  - infrastructure/model-cache
  - infrastructure/multiprocessing
  - infrastructure/ngram-speculator/truss
  - infrastructure/ngram-speculator/trussless
  - infrastructure/paddlepaddle/paddleocr-vl
