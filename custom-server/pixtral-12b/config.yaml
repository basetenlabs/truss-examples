base_image:
  image: vllm/vllm-openai:v0.7.3
model_metadata:
  repo_id: mistralai/Pixtral-12B-2409
  avatar_url: https://cdn.baseten.co/production/static/explore/mistral_logo.png
  example_model_input: {
    "model": "pixtral",
    "messages": [
      {
      "role": "user",
      "content": [
        {
        "type": "text",
        "text": "Describe this image in one sentence."
        },
        {
        "type": "image_url",
        "image_url": {
          "url": "https://picsum.photos/id/237/200/300"
        }
        }
      ]
      }
    ],
    "stream": false,
    "max_tokens": 512,
    "temperature": 0.5
  }
  tags:
    - openai-compatible
    - multimodal
    - text-generation
docker_server:
  start_command: sh -c "VLLM_USE_V1=1 vllm serve mistral-community/pixtral-12b --served-model-name pixtral --tokenizer_mode mistral --max-model-len 65536 --limit_mm_per_prompt 'image=4' --gpu-memory-utilization 0.95"
  readiness_endpoint: /health
  liveness_endpoint: /health
  predict_endpoint: /v1/chat/completions
  server_port: 8000
runtime:
  predict_concurrency : 16
resources:
  accelerator: H100
  use_gpu: true
model_name: Pixtral 12B
environment_variables:
  VLLM_LOGGING_LEVEL: INFO
