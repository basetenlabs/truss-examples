# # Setting up the config.yaml
#
# Running Falcon 7B requires torch, transformers,
# and a few other related libraries.
model_name: "LLM with Streaming"
model_metadata:
    example_model_input: {"prompt": "what is the meaning of life"}
requirements:
- torch==2.0.1
- peft==0.4.0
- scipy==1.11.1
- sentencepiece==0.1.99
- accelerate==0.21.0
- bitsandbytes==0.41.1
- einops==0.6.1
- transformers==4.31.0
# ## Configure resources for Falcon
#
# Note that we need an A10G to run this model.
resources:
  cpu: "3"
  memory: 14Gi
  use_gpu: true
  accelerator: A10G