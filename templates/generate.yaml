mistral/mistral-7b-trt-llm:
  based_on: trt-llm
  config:
    base_image:
      image: docker.io/baseten/triton_trt_llm:v2
    model_metadata:
      avatar_url: https://cdn.baseten.co/production/static/explore/mistral_logo.png
      cover_image_url: https://cdn.baseten.co/production/static/explore/mistral.png
      engine_repository: "baseten/mistral7b-fp16-ifb-2k-2k"
      tokenizer_repository: "mistralai/Mistral-7B-v0.1"
    description: Generate text from a prompt with this seven billion parameter language model.
    model_name: Mistral 7B TRT
  ignore:
    - README.md
  replaces:
    packages/inflight_batcher_llm/ensemble/config.pbtxt:
      from_str: <max_batch_size>
      to_str: 2048
    packages/inflight_batcher_llm/postprocessing/config.pbtxt:
      from_str: <max_batch_size>
      to_str: 2048
    packages/inflight_batcher_llm/preprocessing/config.pbtxt:
      from_str: <max_batch_size>
      to_str: 2048
llama/llama-2-7b-trt-llm:
  based_on: trt-llm
  config:
    model_metadata:
      avatar_url: https://cdn.baseten.co/production/static/explore/meta.png
      cover_image_url: https://cdn.baseten.co/production/static/explore/llama.png
      engine_repository: "baseten/llama_7b_sq0.8_4096ctx_64bs"
      tokenizer_repository: "NousResearch/Llama-2-7b-chat-hf"
    description: Generate text from a prompt with this seven billion parameter language model.
    model_name: Llama 7B Chat TRT
  ignore:
    - README.md
  replaces:
    packages/inflight_batcher_llm/ensemble/config.pbtxt:
      from_str: <max_batch_size>
      to_str: 128
    packages/inflight_batcher_llm/postprocessing/config.pbtxt:
      from_str: <max_batch_size>
      to_str: 128
    packages/inflight_batcher_llm/preprocessing/config.pbtxt:
      from_str: <max_batch_size>
      to_str: 128
