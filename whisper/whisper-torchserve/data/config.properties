inference_address=http://0.0.0.0:8888
batch_size=16
ipex_enable=true
async_logging=true

models={\
  "whisper_base": {\
    "1.0": {\
        "defaultVersion": true,\
        "marName": "whisper_base.mar",\
        "minWorkers": 1,\
        "maxWorkers": 4,\
        "batchSize": 16,\
        "maxBatchDelay": 250,\
        "responseTimeout": 120\
    }\
  }\
}

# maxBatchDelay is the amount of time to wait for the batch size to fill up. Default is 250 ms.
# default_workers_per_model=2
