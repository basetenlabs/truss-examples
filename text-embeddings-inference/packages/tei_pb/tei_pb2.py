# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: tei.proto
# Protobuf Python Version: 5.26.1
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\ttei.proto\x12\x06tei.v1\"\r\n\x0bInfoRequest\"\xa3\x03\n\x0cInfoResponse\x12\x0f\n\x07version\x18\x01 \x01(\t\x12\x10\n\x03sha\x18\x02 \x01(\tH\x00\x88\x01\x01\x12\x19\n\x0c\x64ocker_label\x18\x03 \x01(\tH\x01\x88\x01\x01\x12\x10\n\x08model_id\x18\x04 \x01(\t\x12\x16\n\tmodel_sha\x18\x05 \x01(\tH\x02\x88\x01\x01\x12\x13\n\x0bmodel_dtype\x18\x06 \x01(\t\x12%\n\nmodel_type\x18\x07 \x01(\x0e\x32\x11.tei.v1.ModelType\x12\x1f\n\x17max_concurrent_requests\x18\x08 \x01(\r\x12\x18\n\x10max_input_length\x18\t \x01(\r\x12\x18\n\x10max_batch_tokens\x18\n \x01(\r\x12\x1f\n\x12max_batch_requests\x18\x0b \x01(\rH\x03\x88\x01\x01\x12\x1d\n\x15max_client_batch_size\x18\x0c \x01(\r\x12\x1c\n\x14tokenization_workers\x18\r \x01(\rB\x06\n\x04_shaB\x0f\n\r_docker_labelB\x0c\n\n_model_shaB\x15\n\x13_max_batch_requests\"\xa0\x01\n\x08Metadata\x12\x15\n\rcompute_chars\x18\x01 \x01(\r\x12\x16\n\x0e\x63ompute_tokens\x18\x02 \x01(\r\x12\x15\n\rtotal_time_ns\x18\x03 \x01(\x04\x12\x1c\n\x14tokenization_time_ns\x18\x04 \x01(\x04\x12\x15\n\rqueue_time_ns\x18\x05 \x01(\x04\x12\x19\n\x11inference_time_ns\x18\x06 \x01(\x04\"C\n\x0c\x45mbedRequest\x12\x0e\n\x06inputs\x18\x01 \x01(\t\x12\x10\n\x08truncate\x18\x02 \x01(\x08\x12\x11\n\tnormalize\x18\x03 \x01(\x08\"G\n\rEmbedResponse\x12\x12\n\nembeddings\x18\x01 \x03(\x02\x12\"\n\x08metadata\x18\x02 \x01(\x0b\x32\x10.tei.v1.Metadata\"6\n\x12\x45mbedSparseRequest\x12\x0e\n\x06inputs\x18\x01 \x01(\t\x12\x10\n\x08truncate\x18\x02 \x01(\x08\"+\n\x0bSparseValue\x12\r\n\x05index\x18\x01 \x01(\r\x12\r\n\x05value\x18\x02 \x01(\x02\"i\n\x13\x45mbedSparseResponse\x12.\n\x11sparse_embeddings\x18\x01 \x03(\x0b\x32\x13.tei.v1.SparseValue\x12\"\n\x08metadata\x18\x02 \x01(\x0b\x32\x10.tei.v1.Metadata\"3\n\x0f\x45mbedAllRequest\x12\x0e\n\x06inputs\x18\x01 \x01(\t\x12\x10\n\x08truncate\x18\x02 \x01(\x08\"$\n\x0eTokenEmbedding\x12\x12\n\nembeddings\x18\x01 \x03(\x02\"h\n\x10\x45mbedAllResponse\x12\x30\n\x10token_embeddings\x18\x01 \x03(\x0b\x32\x16.tei.v1.TokenEmbedding\x12\"\n\x08metadata\x18\x02 \x01(\x0b\x32\x10.tei.v1.Metadata\"F\n\x0ePredictRequest\x12\x0e\n\x06inputs\x18\x01 \x01(\t\x12\x10\n\x08truncate\x18\x02 \x01(\x08\x12\x12\n\nraw_scores\x18\x03 \x01(\x08\"J\n\x12PredictPairRequest\x12\x0e\n\x06inputs\x18\x01 \x03(\t\x12\x10\n\x08truncate\x18\x02 \x01(\x08\x12\x12\n\nraw_scores\x18\x03 \x01(\x08\"*\n\nPrediction\x12\r\n\x05score\x18\x01 \x01(\x02\x12\r\n\x05label\x18\x02 \x01(\t\"^\n\x0fPredictResponse\x12\'\n\x0bpredictions\x18\x01 \x03(\x0b\x32\x12.tei.v1.Prediction\x12\"\n\x08metadata\x18\x02 \x01(\x0b\x32\x10.tei.v1.Metadata\"h\n\rRerankRequest\x12\r\n\x05query\x18\x01 \x01(\t\x12\r\n\x05texts\x18\x02 \x03(\t\x12\x10\n\x08truncate\x18\x03 \x01(\x08\x12\x12\n\nraw_scores\x18\x04 \x01(\x08\x12\x13\n\x0breturn_text\x18\x05 \x01(\x08\"m\n\x13RerankStreamRequest\x12\r\n\x05query\x18\x01 \x01(\t\x12\x0c\n\x04text\x18\x02 \x01(\t\x12\x10\n\x08truncate\x18\x03 \x01(\x08\x12\x12\n\nraw_scores\x18\x04 \x01(\x08\x12\x13\n\x0breturn_text\x18\x05 \x01(\x08\"@\n\x04Rank\x12\r\n\x05index\x18\x01 \x01(\r\x12\x11\n\x04text\x18\x02 \x01(\tH\x00\x88\x01\x01\x12\r\n\x05score\x18\x03 \x01(\x02\x42\x07\n\x05_text\"Q\n\x0eRerankResponse\x12\x1b\n\x05ranks\x18\x01 \x03(\x0b\x32\x0c.tei.v1.Rank\x12\"\n\x08metadata\x18\x02 \x01(\x0b\x32\x10.tei.v1.Metadata\";\n\rEncodeRequest\x12\x0e\n\x06inputs\x18\x01 \x01(\t\x12\x1a\n\x12\x61\x64\x64_special_tokens\x18\x02 \x01(\x08\"r\n\x0bSimpleToken\x12\n\n\x02id\x18\x01 \x01(\r\x12\x0c\n\x04text\x18\x02 \x01(\t\x12\x0f\n\x07special\x18\x03 \x01(\x08\x12\x12\n\x05start\x18\x04 \x01(\rH\x00\x88\x01\x01\x12\x11\n\x04stop\x18\x05 \x01(\rH\x01\x88\x01\x01\x42\x08\n\x06_startB\x07\n\x05_stop\"5\n\x0e\x45ncodeResponse\x12#\n\x06tokens\x18\x01 \x03(\x0b\x32\x13.tei.v1.SimpleToken\"9\n\rDecodeRequest\x12\x0b\n\x03ids\x18\x01 \x03(\r\x12\x1b\n\x13skip_special_tokens\x18\x02 \x01(\x08\"\x1e\n\x0e\x44\x65\x63odeResponse\x12\x0c\n\x04text\x18\x01 \x01(\t*Y\n\tModelType\x12\x18\n\x14MODEL_TYPE_EMBEDDING\x10\x00\x12\x19\n\x15MODEL_TYPE_CLASSIFIER\x10\x01\x12\x17\n\x13MODEL_TYPE_RERANKER\x10\x02\x32>\n\x04Info\x12\x36\n\x04Info\x12\x13.tei.v1.InfoRequest\x1a\x14.tei.v1.InfoResponse\"\x03\x90\x02\x02\x32\x9f\x03\n\x05\x45mbed\x12\x34\n\x05\x45mbed\x12\x14.tei.v1.EmbedRequest\x1a\x15.tei.v1.EmbedResponse\x12>\n\x0b\x45mbedStream\x12\x14.tei.v1.EmbedRequest\x1a\x15.tei.v1.EmbedResponse(\x01\x30\x01\x12\x46\n\x0b\x45mbedSparse\x12\x1a.tei.v1.EmbedSparseRequest\x1a\x1b.tei.v1.EmbedSparseResponse\x12P\n\x11\x45mbedSparseStream\x12\x1a.tei.v1.EmbedSparseRequest\x1a\x1b.tei.v1.EmbedSparseResponse(\x01\x30\x01\x12=\n\x08\x45mbedAll\x12\x17.tei.v1.EmbedAllRequest\x1a\x18.tei.v1.EmbedAllResponse\x12G\n\x0e\x45mbedAllStream\x12\x17.tei.v1.EmbedAllRequest\x1a\x18.tei.v1.EmbedAllResponse(\x01\x30\x01\x32\x9d\x02\n\x07Predict\x12:\n\x07Predict\x12\x16.tei.v1.PredictRequest\x1a\x17.tei.v1.PredictResponse\x12\x42\n\x0bPredictPair\x12\x1a.tei.v1.PredictPairRequest\x1a\x17.tei.v1.PredictResponse\x12\x44\n\rPredictStream\x12\x16.tei.v1.PredictRequest\x1a\x17.tei.v1.PredictResponse(\x01\x30\x01\x12L\n\x11PredictPairStream\x12\x1a.tei.v1.PredictPairRequest\x1a\x17.tei.v1.PredictResponse(\x01\x30\x01\x32\x88\x01\n\x06Rerank\x12\x37\n\x06Rerank\x12\x15.tei.v1.RerankRequest\x1a\x16.tei.v1.RerankResponse\x12\x45\n\x0cRerankStream\x12\x1b.tei.v1.RerankStreamRequest\x1a\x16.tei.v1.RerankResponse(\x01\x32\x86\x02\n\x08Tokenize\x12\x39\n\x08Tokenize\x12\x15.tei.v1.EncodeRequest\x1a\x16.tei.v1.EncodeResponse\x12\x43\n\x0eTokenizeStream\x12\x15.tei.v1.EncodeRequest\x1a\x16.tei.v1.EncodeResponse(\x01\x30\x01\x12\x37\n\x06\x44\x65\x63ode\x12\x15.tei.v1.DecodeRequest\x1a\x16.tei.v1.DecodeResponse\x12\x41\n\x0c\x44\x65\x63odeStream\x12\x15.tei.v1.DecodeRequest\x1a\x16.tei.v1.DecodeResponse(\x01\x30\x01\x62\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'tei_pb2', _globals)
if not _descriptor._USE_C_DESCRIPTORS:
  DESCRIPTOR._loaded_options = None
  _globals['_INFO'].methods_by_name['Info']._loaded_options = None
  _globals['_INFO'].methods_by_name['Info']._serialized_options = b'\220\002\002'
  _globals['_MODELTYPE']._serialized_start=2145
  _globals['_MODELTYPE']._serialized_end=2234
  _globals['_INFOREQUEST']._serialized_start=21
  _globals['_INFOREQUEST']._serialized_end=34
  _globals['_INFORESPONSE']._serialized_start=37
  _globals['_INFORESPONSE']._serialized_end=456
  _globals['_METADATA']._serialized_start=459
  _globals['_METADATA']._serialized_end=619
  _globals['_EMBEDREQUEST']._serialized_start=621
  _globals['_EMBEDREQUEST']._serialized_end=688
  _globals['_EMBEDRESPONSE']._serialized_start=690
  _globals['_EMBEDRESPONSE']._serialized_end=761
  _globals['_EMBEDSPARSEREQUEST']._serialized_start=763
  _globals['_EMBEDSPARSEREQUEST']._serialized_end=817
  _globals['_SPARSEVALUE']._serialized_start=819
  _globals['_SPARSEVALUE']._serialized_end=862
  _globals['_EMBEDSPARSERESPONSE']._serialized_start=864
  _globals['_EMBEDSPARSERESPONSE']._serialized_end=969
  _globals['_EMBEDALLREQUEST']._serialized_start=971
  _globals['_EMBEDALLREQUEST']._serialized_end=1022
  _globals['_TOKENEMBEDDING']._serialized_start=1024
  _globals['_TOKENEMBEDDING']._serialized_end=1060
  _globals['_EMBEDALLRESPONSE']._serialized_start=1062
  _globals['_EMBEDALLRESPONSE']._serialized_end=1166
  _globals['_PREDICTREQUEST']._serialized_start=1168
  _globals['_PREDICTREQUEST']._serialized_end=1238
  _globals['_PREDICTPAIRREQUEST']._serialized_start=1240
  _globals['_PREDICTPAIRREQUEST']._serialized_end=1314
  _globals['_PREDICTION']._serialized_start=1316
  _globals['_PREDICTION']._serialized_end=1358
  _globals['_PREDICTRESPONSE']._serialized_start=1360
  _globals['_PREDICTRESPONSE']._serialized_end=1454
  _globals['_RERANKREQUEST']._serialized_start=1456
  _globals['_RERANKREQUEST']._serialized_end=1560
  _globals['_RERANKSTREAMREQUEST']._serialized_start=1562
  _globals['_RERANKSTREAMREQUEST']._serialized_end=1671
  _globals['_RANK']._serialized_start=1673
  _globals['_RANK']._serialized_end=1737
  _globals['_RERANKRESPONSE']._serialized_start=1739
  _globals['_RERANKRESPONSE']._serialized_end=1820
  _globals['_ENCODEREQUEST']._serialized_start=1822
  _globals['_ENCODEREQUEST']._serialized_end=1881
  _globals['_SIMPLETOKEN']._serialized_start=1883
  _globals['_SIMPLETOKEN']._serialized_end=1997
  _globals['_ENCODERESPONSE']._serialized_start=1999
  _globals['_ENCODERESPONSE']._serialized_end=2052
  _globals['_DECODEREQUEST']._serialized_start=2054
  _globals['_DECODEREQUEST']._serialized_end=2111
  _globals['_DECODERESPONSE']._serialized_start=2113
  _globals['_DECODERESPONSE']._serialized_end=2143
  _globals['_INFO']._serialized_start=2236
  _globals['_INFO']._serialized_end=2298
  _globals['_EMBED']._serialized_start=2301
  _globals['_EMBED']._serialized_end=2716
  _globals['_PREDICT']._serialized_start=2719
  _globals['_PREDICT']._serialized_end=3004
  _globals['_RERANK']._serialized_start=3007
  _globals['_RERANK']._serialized_end=3143
  _globals['_TOKENIZE']._serialized_start=3146
  _globals['_TOKENIZE']._serialized_end=3408
# @@protoc_insertion_point(module_scope)