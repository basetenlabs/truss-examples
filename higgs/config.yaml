description: Higgs Audio v2 Generation 3B - Audio generation model with vLLM
base_image:
  image: bosonai/higgs-audio-vllm:latest
model_metadata:
  repo_id: bosonai/higgs-audio-v2-generation-3B-base
  example_model_input: {
    "model": "higgs-audio-v2-generation-3B-base",
    "messages": [
      {
        "role": "user",
        "content": [
          {
            "type": "text",
            "text": "Generate audio based on this description"
          },
          {
            "type": "audio_url",
            "audio_url": {"url": "https://example.com/sample.wav"}
          }
        ]
      }
    ],
    "max_tokens": 512,
    "temperature": 0.7
  }
  tags:
    - openai-compatible
    - audio-generation
    - multimodal
docker_server:
  start_command: sh -c "vllm serve bosonai/higgs-audio-v2-generation-3B-base --served-model-name higgs-audio-v2-generation-3B-base --limit-mm-per-prompt audio=50 --max-model-len 8192 --port 8000 --gpu-memory-utilization 0.8 --disable-mm-preprocessor-cache"
  readiness_endpoint: /health
  liveness_endpoint: /health
  predict_endpoint: /v1/chat/completions
  server_port: 8000
resources:
  accelerator: H100
  use_gpu: true
runtime:
  predict_concurrency: 16
model_name: Higgs Audio v2 Generation 3B
environment_variables:
  VLLM_LOGGING_LEVEL: INFO
