# Truss Examples — Project Rules

This repo contains production-ready inference examples for Truss. Follow these rules when creating, editing, or reviewing examples.

## Repository structure

Top-level directories:

- `tutorials/` — Getting-started guides (BERT, LLMs, streaming, image generation, caching, batching)
- `llm/` — Text generation models, organized by family (`llm/llama/`, `llm/qwen/`, `llm/mistral/`, etc.)
- `embeddings/` — Embedding and reranker models (`bei/`, `tei/`, `clip/`)
- `image/` — Image generation, editing, segmentation (`stable-diffusion/`, `flux/`, `segment-anything/`)
- `audio/` — Speech-to-text, TTS, music generation (`whisper/`, `kokoro/`, `musicgen-large/`)
- `optimized/` — Autogenerated TRT-LLM configs (`briton/`, `bisv2/`)
- `infrastructure/` — Patterns and techniques (custom servers, gRPC, model caching, chains)
- `_internal/` — Build tooling, templates, test scripts (not customer-facing)
- `_archive/` — Deprecated examples

## Placement rules

| Model type | Directory | Example |
|---|---|---|
| Text generation / chat / LLM | `llm/<family>/` | `llm/llama/tinyllama-1.1B-chat-v1.0` |
| Embedding or reranker | `embeddings/bei/`, `embeddings/tei/`, or `embeddings/clip/` | `embeddings/bei/baai-bge-large-en-v1.5-embedding` |
| Image generation or processing | `image/` or `image/<family>/` | `image/stable-diffusion/stable-diffusion-xl-1.0` |
| Audio (STT, TTS, music) | `audio/` | `audio/whisper/faster-whisper-v3` |
| Infrastructure pattern | `infrastructure/` | `infrastructure/model-cache` |
| Getting-started tutorial | `tutorials/` | `tutorials/getting-started-bert` |

## Naming conventions

- Use hyphens, not underscores: `falcon-7b` not `falcon_7b`
- Do not include "truss" in folder names: `falcon-7b` not `falcon-7b-truss`
- Include parameter count when multiple variants exist: `Falcon 7B` not `Falcon`
- All directory names should be lowercase

## config.yaml requirements

Always include:
- `model_name`
- `description` (one-sentence summary)
- `model_metadata.example_model_input`

Recommended:
- `model_metadata.repo_id` (Hugging Face model ID)
- `model_metadata.avatar_url` (128x128 PNG)
- `model_metadata.cover_image_url` (452x423 PNG)
- `model_metadata.tags`

### Requirements pinning

Pin versions for ALL Python requirements:

```yaml
requirements:
- accelerate==0.20.3
- torch==2.0.1
- transformers==4.30.2
```

Never leave a requirement unpinned. For git+ dependencies, pin to a specific commit hash, not `@master` or `@main`.

### Secrets

If the model requires a HuggingFace token, always name the secret `hf_access_token`:

```yaml
secrets:
  hf_access_token: "ENTER HF ACCESS TOKEN HERE"
```

### Hardware

Configure with the least expensive hardware that runs at reasonable speed and quality. Note tradeoffs in the README when applicable.

## README template

Every example must include a `README.md` following this structure:

```markdown
# <Model Name>

<One or two sentence description.>

## Deploying <Model Name>

<Deploy instructions with `truss push <path>`.>

## Invoking <Model Name>

<Curl or Python snippet with example input and expected output.>
```

- Deploy path must match the actual directory path relative to repo root
- OpenAI-compatible models must show `/v1/chat/completions` endpoint
- Never use `--trusted` or `--publish` flags
- If the config requires `hf_access_token`, the README must mention setting up the secret

Reference example: `image/stable-diffusion/stable-diffusion-xl-1.0`

## Model I/O conventions

- Models that support streaming should accept a `stream` kwarg defaulting to false
- Models that take text input should call the parameter `prompt`

## CI

Active examples should be listed in `ci.yaml` at the repo root. The test suite (`_internal/bin/test_all.py`) validates all configs, READMEs, naming, links, pinning, and CI completeness.

Run tests locally:
```bash
python _internal/bin/test_all.py           # default
python _internal/bin/test_all.py --verbose  # show every check
python _internal/bin/test_all.py --category llm  # filter by category
```

## Automatic documentation

To include an example in auto-generated docs on https://truss.baseten.co/, add a `doc.yaml`:

```yaml
title: "Text-to-image"
description: "Building a text-to-image model with SDXL"
files:
  - model/model.py
  - config.yaml
```
